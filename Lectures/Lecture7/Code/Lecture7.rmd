```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introduction

Load packages:
```{r, message = FALSE, warning = FALSE}
library(tidyverse)
library(gapminder)
library(panelr)
library(plm)
library(fixest)
library(lmtest) 
library(multiwayvcov)
library(broom)
```

Resources used to create this lesson:

- https://www.econometrics-with-r.org/10-3-fixed-effects-regression.html


# What is panel data?

**Panel data**--also referred to as **longitudinal data**--refers to information obtained from observing the *same set of entities at multiple points in time*. 

Some examples: 

- A sample of youth observed every year to assess their educational achievement and subsequent employment outcomes 
  + in this example the *entities* are individuals and the time periods are years 
- A sample of businesses surveyed every month since the beginning of the pandemic
  + in this example the *entities* are businesses and the time periods are months
- Administrative units (e.g. provinces) report quarterly information on hate crimes
  + in this example the *entities* are provinces and the time periods are quarters
  
When observations span multiple time periods, the critical distinction between **panel data** and **pooled cross-sectional data** is that in the former the *same entities* are observed repeatedly over time, while in the latter *different entities* are observed in each time period.


# Key advantage of panel data: exploiting within-entity variation

Comparisons between entities in the same period are often susceptible to omitted variable bias. Say we're interested in evaluating the impact of national mask mandates on pandemic outcomes. Countries with national mask mandates may also be implementing additional public health measures, face different economic conditions, and may be responding to being harder hit by the pandemic. 

Thus comparing COVID cases per capita between countries with/without national mask mandates in a given month amounts to comparing countries that are very different in terms of other factors driving pandemic outcomes; in other words, comparisons between "treated" and "untreated" countries within a cross-section (e.g. a given month) may not be very informative, as any association between the mask-mandate "treatment" and outcomes may in large part be explained by these other factors.

In this example, **exploiting cross-sectional variation (*****between*** **countries within one period) to identify the impacts of a mask-mandate is very prone to bias** (omitted variable bias and reverse causality).

With panel data, one can **exploit variation in the mask-mandate treatment over time** ***within*** **countries** to identify the impacts of a mask-mandate. More specifically, in this example fixed effects can be used to control for two broad categories of potentially confounding factors: (1) fixed (time-invariant) country-specific differences; and (2) time-varying differences shared by all countries.

Note how salient the major limitation of fixed effects models is in this example: any factors that within-countries over time cannot be accounted for with fixed effects. Said another way, you can't have country-month fixed effects, because *that would attempt to control for the policy variable under consideration*; it would introduce perfect multicollinearity between the treatment dummy variable and the corresponding country-year fixed effect, leading one of them to be dropped from the regression).

What's an example of a threat to internal validity that fixed effects can't account for this research question? If a particular country's decision to implement a national mask mandate is made in tandem with other effective public health measures like free testing programs, then it is impossible to distinguish between the relative contributions of these two policies using fixed effects alone. Maybe you can start to explicitly control for these other policies and other confounding factors with the available data, but trying to explicitly control for all observable sources of OVB seems like a losing battle in this case.


***Self-assessment question:*** 

*Given the hypothetical panel data structure implied above, can you think of additional research design features and/or data that might help researchers to distinguish the impacts of a mask-mandate from any national testing policies implemented at the same time?*


# Panel data structure


## Long-form panel data

Just because the underlying data is panel in nature doesn't mean the input data is structured in a useful way.

Fixed effects regression analysis generally require **long-form panel data**: each observation represents a unique entity-time period pairing (e.g. country-month).

Using the familiar gapminder data, we can confirm that this data frame is long-form panel data with one observation for each surveyed country (or reporting unit like provinces!) every 5 years.

```{r}
head(gapminder, n = 20)
```


## Wide-form panel data

Alternatively, panel data can be structured in **wide form**, where the unit of observation in the data frame is the entity (here: country), and the observed values for each entity across different time periods appear as separate columns of data (e.g. lifeExp1952, lifeExp1957,..., lifeExp2007). 

One advantage to wide-form panel data is that it is generally easier to compute some country-level statistics; e.g. the change in life expectancy from 1952 to 2007 for each country can be easily computed as the difference between the lifeExp1952 and lifeExp2007 columns.


## Reshaping data

So if wanted to get the gapminder data frame in wide form to obtain entity-level statics, how can we go about that?

The `tidyr` package include a number of useful functions for restructuring data frames, including `pivot_longer` and `pivot_wider` that we used in Week 6 (Women in STEM).

The `panelr` package also has its own functions for reshaping panel data and estimating panel data models, which we'll use here. First call the `panel_data()` function to tell R the nature of the panel data frame: use the `id` argument to specify the entity variable, and the `wave` argument to specify the time variable.

From there one can use the `long_panel()` and `widen_panel()` functions to move between long- and wide-form data as needed, as in the following code example.

```{r}
#use the panel_data function to specify panel nature
gap <- panel_data(gapminder, id = country, wave = year)

#reshape gap from long to wide form data
gap_wide <- widen_panel(gap)

#confirm reshape and dimensions of wide data
dim(gap_wide)
head(gap_wide)

#reshape back to wide from long (creates a row for every year, we'll drop NA rows later)
gap_long_temp <- long_panel(gap_wide, 
                            prefix = "_", 
                            begin = 1952, 
                            end = 2007,
                            id = "country") %>% 
  rename(year = wave)
head(gap_long_temp)

#drop rows with NA values
gap_long <- gap_long_temp %>% na.omit(lifeExp)

#confirm reshape and dimensions of long data
dim(gap_long)
head(gap_long)
```

The following is a visual representation of reshaping from long to wide form data and vice versa from [Manny Gimond's EDA Course ](https://mgimond.github.io/ES218/Week03b.html#creating_a_wide_table_from_a_long_table){target="_blank"}.

![](longtowide.JPG){width=100%}

<br>

![](widetolong.JPG){width=100%}



# Fixed effects estimation

Fixed effects models allow us to control for certain kinds of unobserved factors (unobserved = not observed in the data): (1) factors that vary between entities but are constant over time; and (2) factors that vary over time that are shared by all entities. We can account for these type of factors in a regression model without observing them in the data--otherwise omitted variables--by incorporating entity fixed effects and time fixed effects, respectively. 

Also note that in a conventional panel data setting you can choose to include both entity and time fixed effects, one, or neither. The decision to incorporate fixed effects should be done carefully as a reasoned strategy for controlling for unobserved factors that could result in biased coefficient estimates of interest.

In addition to the fixed effects [video lecture](https://drive.google.com/file/d/1NPCtAUMg9eocWBaPr5jaY3KgsbxPkkeD/view?usp=sharing) from Quant II, you can consult Chapter 10 of [Introduction to Econometrics with R](https://www.econometrics-with-r.org/10-rwpd.html) for a review of fixed effects regression theory along with R code. The following is an excerpt from that chapter that summarizes two equivalent approaches for using R to estimate fixed effects models: the Least Squares Dummy Variable model, and traditional fixed effects models.

******

Consider the panel regression model

<p><span class="math display">\[Y_{it} = \beta_0 + \beta_1 X_{it} + \beta_2 Z_i +  u_{it}\]</span>
where the <span class="math inline">\(Z_i\)</span> are unobserved time-invariant heterogeneities across the entities <span class="math inline">\(i=1,\dots,n\)</span>. We aim to estimate <span class="math inline">\(\beta_1\)</span>, the effect on <span class="math inline">\(Y_i\)</span> of a change in <span class="math inline">\(X_i\)</span> holding constant <span class="math inline">\(Z_i\)</span>. Letting <span class="math inline">\(\alpha_i = \beta_0 + \beta_2 Z_i\)</span> we obtain the model
<span class="math display" id="eq:femodel">\[\begin{align}
Y_{it} = \alpha_i + \beta_1 X_{it} + u_{it} \tag{10.1}.
\end{align}\]</span>
Having individual specific intercepts <span class="math inline">\(\alpha_i\)</span>, <span class="math inline">\(i=1,\dots,n\)</span>, where each of these can be understood as the fixed effect of entity <span class="math inline">\(i\)</span>, this model is called the <em>fixed effects model</em>.
The variation in the <span class="math inline">\(\alpha_i\)</span>, <span class="math inline">\(i=1,\dots,n\)</span> comes from the <span class="math inline">\(Z_i\)</span>. <a href="10-3-fixed-effects-regression.html#eq:femodel">(10.1)</a> can be rewritten as a regression model containing <span class="math inline">\(n-1\)</span> dummy regressors and a constant:
<span class="math display" id="eq:drmodel">\[\begin{align}
Y_{it} = \beta_0 + \beta_1 X_{it} + \gamma_2 D2_i + \gamma_3 D3_i + \cdots + \gamma_n Dn_i + u_{it} \tag{10.2}.
\end{align}\]</span>
Model <a href="10-3-fixed-effects-regression.html#eq:drmodel">(10.2)</a> has <span class="math inline">\(n\)</span> different intercepts — one for every entity. <a href="10-3-fixed-effects-regression.html#eq:femodel">(10.1)</a> and <a href="10-3-fixed-effects-regression.html#eq:drmodel">(10.2)</a> are equivalent representations of the fixed effects model.</p>
<p>The fixed effects model can be generalized to contain more than just one determinant of <span class="math inline">\(Y\)</span> that is correlated with <span class="math inline">\(X\)</span> and changes over time.

******

If specified properly, estimating a fixed effects model (as in 10.1) and a Least Squares Dummy Variable (LSDV) model (as in 10.2) will yield identical estimates for <span class="math inline">\(\beta_1\)</span>. The LSDV model will also report estimates for every "fixed effect" coefficient, whereas the fixed effects model will *sweep away* these fixed effects rather than estimating them; this happens by *residualizing* (or *demeaning*) the underlying data, as outlined in the fixed effects [video lecture](https://drive.google.com/file/d/1NPCtAUMg9eocWBaPr5jaY3KgsbxPkkeD/view?usp=sharing) from Quant II.

Also note that you need to think carefully about the underlying error structure when estimating standard errors for inference on <span class="math inline">\(\hat\beta_1\)</span>. Examples of R functions for clustered standard errors for the LSDV and fixed effects models can be found below in Sections 5.1 and 5.2.


## Least Squares Dummy Variable model estimation

The LSDV model can be estimated in R using the `lm()` function. The code examples below use the gapminder panel data frame to estimate the impact of GDP per capita on life expectancy with fixed effects for country and year (wave).

```{r}
#specify LSDV model
lsdv1 <- lm(lifeExp ~ gdpPercap + factor(country) + factor(year), data = gap_long)
```

```{r, collapse= TRUE}
#display R-squared and Adj. R-squared for full model
summary(lsdv1)$r.squared
summary(lsdv1)$adj.r.squared
```

```{r}
#"regular" SEs (homoskedasticity-only)
coeftest(lsdv1)[2,]

#robust SEs (here we're just reporting on the coefficient for gdpPercap)
coeftest(lsdv1, vcov = vcovHC(lsdv1, type = "HC1"))[2,]
```

The results are identical to Stata when using the *areg* command (or *regress*, properly specified):

![](gap-stata-robust.PNG){width=60%}

<br>

```{r}
#clustered SEs by country (equivalent to areg in Stata)

  #stats for coefficient of interest is the 2nd element in this object. 
  lsdv1_vcov <- cluster.vcov(lsdv1, 
                              gap_long$country,
                              df_correction = T) #a small sample size adjustment
    
  #just report stats for coefficient of interest (the second row from coeftest)
    coeftest(lsdv1, lsdv1_vcov)[2,] 
```

Here are the identical clustered SEs from Stata using the *areg* command:

![](gap-stata-cluster.PNG){width=60%}

<br>

Also note that the estimated slope effect of GDP per capita on life expectancy is negative! (Try running without year fixed effects and see how the estimated slope effect changes.) In other words, once we control for time-invariant country-specific characteristics and year-specific factors shared by all countries, we estimate a negative association between GDP per capita and life expectancy -- this seems contrary to our expectations!


## Fixed effects estimation with `feols()` and `plm()`


`feols()` in the `fixest` package is another way to estimate fixed effects models, and is particularly good at handling lots of fixed effects terms really fast.

```{r}
#specify model with FEs for country and year, and robust SEs
feols_robust <- feols(lifeExp ~ gdpPercap | factor(country) + factor(year), 
                data = gap_long,
                vcov = "hetero")
#obtain results
summary(feols_robust) 
#you can also use tidy in the broom package to obtain results
tidy(feols_robust) %>% filter(term == "gdpPercap")
```

```{r}
#specify model with FEs for country and year, and cluster robust SEs by country
feols_ccluster <- feols(lifeExp ~ gdpPercap | factor(country) + factor(year), 
                data = gap_long,)
summary(feols_ccluster, cluster = ~ factor(country)) 
```

Note that here the clustered SEs differ slightly from the `lm()` approach and Stata with *areg*, due to a different sample size adjustment with `feols()`.

[Here](https://evalf21.classes.andrewheiss.com/example/standard-errors/) is a helpful resource for obtaining robust and clustered SEs in R, with comparisons to Stata.

While `feols()` is pretty easy to use, it isn't supported by the `stargazer` package for formatting regression output that we'll be introducing later in the semester. For this reason, you may need to rely on `lm()` or the `plm()` function in the package of the same name for displaying formatted regression tables. Here is the code to replicate the above fixed estimation using `plm`:

```{r message=FALSE, warning=FALSE}
#specify FE model using plm
fe1 <- plm(lifeExp ~ gdpPercap, 
          data = gap_long,
          index = c("year", "country"), 
          model = "within", 
          effect = "twoways")
```

```{r message=FALSE, warning=FALSE}
summary(fe1) #note that the R-squared reported w/plm does not reflect the full model!
```

The R-squared reported by `plm()` is known as the "within R-squared"; it tells us how much of the variance within the panel units (here countries) is explained by the model.

```{r message=FALSE, warning=FALSE}
#robust SEs
coeftest(fe1, vcov = vcovHC(fe1, type = "HC1"))
```

[Here](https://alex.miller.im/posts/when-to-use-fixed-effects-vs-clustered-standard-errors-panel-data/) is a very short overview of the motivation for clustered standard errors in panel data settings along with some practical guidance, and here is a short [video lecture](https://drive.google.com/file/d/1VJk5VGqJ4hyVxt8c-tboLQy-8K7zCa5C/view?usp=sharing) on the topic from Quant II.

Some additional practical guidance to keep in mind: clustered standard errors generally lead to over-rejection of the null hypothesis when the number of clusters is small (<50). See [Cameron and Miller (2015)](http://cameron.econ.ucdavis.edu/research/Cameron_Miller_JHR_2015_February.pdf) for more details.


## Visualizing fixed effects results

In the fixed effects models estimated above, life expectancy is regressed on GDP capita with fixed effects for country and year. How can we think about visualizing the results of this fixed effects model? Let's start by writing out the population regression function (PRF), 

$$lifeExp_{ct} = \beta_0 + \beta_1 gdpPercap_{ct} + \phi_c + \theta_t + u_{ct} \tag{1}$$
where *c* indexes countries and *t* indexes years. For notational purposes we generally prefer the traditional FE model notation, since we often aren't interested in the values of the fixed effect terms themselves (we just want to use them to control for certain types of omitted variables). But it can still be instructive to return to the LSDV framework to understand what we're estimating.

The LSDV model reminds us that we are estimating a single slope effect for GDP per capita, but we are allowing for different intercepts for every country and year. So we could plot separate regression lines to illustrate how the linear relationship between GDP per capita and life expectancy differs for every single country in 2007, for example; all the regression lines would be parallel, only the intercepts would differ. 

In many cases, including this one, that approach would result in way too many regression lines on the same plot -- it would just look like a big mess to have separate regression lines for every country in 2007. Moreover, we're probably not even interested in visualizing different intercepts between countries. Rather, the point is to control for these differences so they aren't a source of omitted variable bias when estimating $\beta_1$, the slope effect of GDP per capita on life expectancy.

Hence the more common FE notation seen in equation (1), rather than the LSDV model. Estimation of equation 1 is implemented by using ***residualized*** (or *demeaned*) versions of GDP per capita and life expectancy. That's what FE commands like `plm()` in R and areg in Stata do. First, they regress the outcome (lifeExp) on dummy variables for every country and year, and then obtain the residual for every observation. This residual represents the variation in the outcome that is *not* explained by time-invariant country-specific characteristics, or year-specific factors shared by all countries. The regressor of interest (gdpPercap) is residualized in a similar fashion. Then the FE coefficient estimate for $\beta_1$ can be obtained by regressing residualized life expectancy on residualized GDP per capita.

With this process in mind, a natural visualization of the FE coefficient estimate of interest is to plot the regression line over the scatterplot of *residualized* GDP per capita vs *residualized* life expectancy.

```{r}
#obtain residualized lifeExp and gdpPercap (with country and year FEs)
lifeExp_r <- resid(lm(gap_long$lifeExp ~ factor(gap_long$country) + factor(gap_long$year)))
gdpPercap_r <- resid(lm(gap_long$gdpPercap ~ factor(gap_long$country) + factor(gap_long$year)))

#add residualized variables to gap_long as new columns (similar to cbind)
gap_long_fe <- data.frame(gap_long, lifeExp_r, gdpPercap_r)

#plot slope effect from FE model over residualized data
ggplot(gap_long_fe, aes(x = gdpPercap_r, y = lifeExp_r)) +
  geom_point(alpha = 0.2) + #adjusts the transparency of the geom_point layer
  geom_smooth(method = 'lm', formula = y ~ x, se = FALSE) +
  ggtitle(label = "Plot of residualized GDP per capita vs residualized life expectancy",
          subtitle = "*Residuals take into account country and year fixed effects")
  
```



# Exploratory data analysis with panel data

When the data includes observations for entities over time and not just a single cross-section of data, we need to think carefully about what sort of descriptive statistics would be informative. More specifically, we usually don't want to compute summary statistics by pooling all observations over time (e.g., a difference in groups means averaged across all times periods). Instead it may be informative to calculate summary statistics separately *within groups*, or *within one or more time periods* (e.g. a difference in group means within in each time period).

Time series plots for different entities (or groups of entities) may be an informative visualization. For example, one could compare time-series plots of key variables averaged over treated entities vs untreated entities, or between some meaningful groups. The following example shows times series plots of life expectancy for countries grouped by continent.

```{r}
#transform data to get continent-year means (bc we observe too many countries to plot separately)
ggplot(data = gap_long, aes(x = year, y = lifeExp, color = continent)) +
  stat_summary(fun = mean, geom = "line") + 
  ggtitle("Life expectancy over time by continent")
```

Also note that the above plot calculates the unweighted mean of lifeExp across all countries for a given continent-year grouping. If we wanted to report population-weighted means for each continent-year, we would need to transform the data frame *before* passing it to `ggplot()`, not from within the `ggplot()` function call. This is because the ggplot statistical transformation `stat_summary()` doesn't accept weights as an argument to allow for weighted mean calculations.

